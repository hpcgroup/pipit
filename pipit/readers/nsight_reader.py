#import essential libraries
import numpy as np
import pandas as pd
import pipit.tracedata



#reader for trace csv reports generated by nsight systems
class NsightReader:
    def __init__(self, nvtx_dir_name, cuda_dir_name, gpu_dir_name):
        #kernexec trace report isn't used as it doesn't provide any information not present in
        #the reports below (except queue times, which can be determined using existing information)

        #possibly take a list of CSVs as the input parameter instead (as many as the user wants to input?)

        self.nvtx_dir_name = nvtx_dir_name #directory of nvtx trace report
        self.cuda_dir_name = cuda_dir_name #directory of cuda api trace report
        self.gpu_dir_name = gpu_dir_name #directory of gpu trace report

    
    def read(self):
        #clean the reports
        nvtx = pd.read_csv(self.nvtx_dir_name, low_memory = False)
        cuda = pd.read_csv(self.cuda_dir_name, low_memory = False)
        gpu = pd.read_csv(self.gpu_dir_name, low_memory = False)

        nvtx.rename(columns = {"Start:ts_ns": "Start (ns)", "End:ts_ns": "End (ns)"}, inplace = True)
        del nvtx["Duration:dur_ns"]
        nvtx["Location ID"] = nvtx["TID"]
        nvtx["Location Type"] = "CPU_THREAD"
        nvtx["Location Group ID"] = nvtx["PID"]
        nvtx["Location Group Type"] = "PROCESS"
        del nvtx["PID"]
        del nvtx["TID"]

        cuda.rename(columns = {"Start Time:ts_ns": "Start (ns)"}, inplace = True)
        cuda["End (ns)"] = cuda["Start (ns)"] + cuda["Duration:dur_ns"]
        del cuda["Duration:dur_ns"]
        cuda["Location ID"] = cuda["Tid"]
        cuda["Location Type"] = "CPU_THREAD"
        cuda["Location Group ID"] = cuda["Pid"]
        cuda["Location Group Type"] = "PROCESS"
        del cuda["Pid"]
        del cuda["Tid"]

        gpu.rename(columns = {"Start:ts_ns": "Start (ns)"}, inplace = True)
        gpu["End (ns)"] = gpu["Start (ns)"] + gpu["Duration:dur_ns"]
        del gpu["Duration:dur_ns"]
        gpu["Location ID"] = gpu["Strm"]
        gpu["Location Type"] = "ACCELERATOR_STREAM"
        gpu["Location Group ID"] = gpu["Ctx"]
        gpu["Location Group Type"] = "ACCELERATOR" #maybe this should be renamed to context id?
        del gpu["Ctx"]
        del gpu["Strm"]


        #create the attributes column
        commonCols = {"Start (ns)", "End (ns)", "Name", "Location ID", "Location Type", "Location Group ID", "Location Group Type"}

        nvtx["Attributes"] = nvtx[set(nvtx.columns) - commonCols].to_dict(orient = "records")
        cuda["Attributes"] = cuda[set(cuda.columns) - commonCols].to_dict(orient = "records")
        gpu["Attributes"] = gpu[set(gpu.columns) - commonCols].to_dict(orient = "records")


        #merge the reports together to generate the final trace
        self.events = nvtx.filter(items = ["Start (ns)", "End (ns)", "Name", "Location ID", "Location Type", "Location Group ID",
                                  "Location Group Type", "Attributes"]).append(cuda.filter(items = ["Start (ns)", "End (ns)", "Name",
                                  "Location ID", "Location Type", "Location Group ID", "Location Group Type","Attributes"]),
                                  ignore_index = True).append(gpu.filter(items = ["Start (ns)", "End (ns)", "Name", "Location ID",
                                  "Location Type", "Location Group ID","Location Group Type", "Attributes"]), ignore_index = True)
        self.events.sort_values(by = ["Start (ns)"], inplace = True)
        self.events.reset_index(drop = True, inplace = True)
        self.events = self.events.astype({"Name": "category", "Location ID": "category", "Location Type": "category",
                                          "Location Group ID": "category", "Location Group Type": "category"})

        #create a second dataframe with leave events
        leaveDF = pd.DataFrame({"Event": np.full((len(self.events),), "Leave"), "Timestamp (ns)": self.events["End (ns)"],
                                "Name": self.events["Name"], "Location ID": self.events["Location ID"],
                                "Location Type": self.events["Location Type"], "Location Group ID": self.events["Location Group ID"],
                                "Location Group Type": self.events["Location Group Type"],
                                "Attributes": np.full((len(self.events),), float("NaN")), "Matching ID": np.arange(len(self.events))})

        #clean up and merge the two together
        self.events.drop(columns = ["End (ns)"], inplace = True)
        self.events.rename(columns = {"Start (ns)": "Timestamp (ns)"}, inplace = True)
        self.events["Event"] = np.full((len(self.events),), "Enter")
        self.events["Matching ID"] = np.arange(len(self.events)) #creates a matching id column by default
        self.events = self.events[["Event", "Timestamp (ns)", "Name", "Location ID", "Location Type", "Location Group ID",
                                   "Location Group Type", "Attributes", "Matching ID"]]

        self.events = self.events.append(leaveDF)
        self.events.sort_values(by = ["Timestamp (ns)"], inplace = True)
        self.events.reset_index(drop = True, inplace = True)
        self.events = self.events.astype({"Event": "category"})


        #return the trace
        return pipit.tracedata.TraceData(None, self.events)
